# Redis问题整理

- [Redis问题整理](#redis问题整理)
  - [Redis 的数据类型及使用场景](#redis-的数据类型及使用场景)
    - [String](#string)
    - [Hash](#hash)
    - [List](#list)
    - [Set](#set)
    - [Sorted Set](#sorted-set)
  - [使用 Redis 有哪些好处？](#使用-redis-有哪些好处)
  - [为什么 使用 Redis 而不是用 Memcache 呢](#为什么-使用-redis-而不是用-memcache-呢)
  - [为什么 Redis 单线程模型效率也能那么高](#为什么-redis-单线程模型效率也能那么高)
  - [说说Redis的线程模型](#说说redis的线程模型)
  - [Redis持久化方式以及区别](#redis持久化方式以及区别)
    - [`RDB` 持久化方式](#rdb-持久化方式)
    - [`RDB`优点](#rdb优点)
    - [`RDB`缺点](#rdb缺点)
    - [AOF=Append-only file 持久化方式](#aofappend-only-file-持久化方式)
    - [`AOF`优点](#aof优点)
    - [`AOF`缺点](#aof缺点)
  - [Redis如何选择持久化方式](#redis如何选择持久化方式)
  - [说说你对Redis事务的理解](#说说你对redis事务的理解)
    - [什么是 Redis 事务？原理是什么？](#什么是-redis-事务原理是什么)
    - [Redis 事务的注意点有哪些？](#redis-事务的注意点有哪些)
    - [Redis 事务为什么不支持回滚？](#redis-事务为什么不支持回滚)
  - [简述Redis集群模式](#简述redis集群模式)
  - [RedisCluster集群原理](#rediscluster集群原理)
  - [RedisCluster集群方案什么情况下会导致整个集群不可用？](#rediscluster集群方案什么情况下会导致整个集群不可用)
  - [缓存和数据库谁先更新呢](#缓存和数据库谁先更新呢)
  - [怎么提高缓存命中率](#怎么提高缓存命中率)
  - [如果有大量的key需要设置同一时间过期，一般需要注意什么](#如果有大量的key需要设置同一时间过期一般需要注意什么)
  - [缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题](#缓存雪崩缓存穿透缓存预热缓存更新缓存降级等问题)
    - [一、缓存雪崩](#一缓存雪崩)
    - [二、缓存穿透](#二缓存穿透)
    - [三、缓存预热](#三缓存预热)
    - [四、缓存更新](#四缓存更新)
    - [五、缓存降级](#五缓存降级)
  - [Redis的数据淘汰策略](#redis的数据淘汰策略)
    - [过期键的清除策略：定时删除和惰性删除](#过期键的清除策略定时删除和惰性删除)
    - [总结：上述两种过期键清除策略都比较极端](#总结上述两种过期键清除策略都比较极端)
    - [解决方案：内存淘汰策略设置](#解决方案内存淘汰策略设置)
  - [简述Redis热点Key及其解决方案](#简述redis热点key及其解决方案)
    - [产生原因和危害](#产生原因和危害)
      - [原因](#原因)
      - [危害](#危害)
    - [发现热点key](#发现热点key)
      - [预估发现](#预估发现)
      - [客户端发现](#客户端发现)
      - [Redis发现](#redis发现)
        - [monitor命令](#monitor命令)
        - [hotkeys](#hotkeys)
      - [抓取TCP包发现](#抓取tcp包发现)
    - [解决热点key](#解决热点key)
      - [使用二级缓存](#使用二级缓存)
      - [key分散](#key分散)
  - [十七、讲一讲Redis缓存的数据一致性问题和处理方案](#十七讲一讲redis缓存的数据一致性问题和处理方案)
    - [数据一致性](#数据一致性)
      - [新增数据类](#新增数据类)
      - [更新缓存类](#更新缓存类)
        - [1、先更新缓存，再更新DB](#1先更新缓存再更新db)
        - [2、先更新DB，再更新缓存](#2先更新db再更新缓存)
      - [删除缓存类](#删除缓存类)
        - [3、先删除缓存，后更新DB](#3先删除缓存后更新db)
        - [4、先更新DB，后删除缓存](#4先更新db后删除缓存)
    - [如何选择问题](#如何选择问题)
  - [哪些操作会阻塞redis](#哪些操作会阻塞redis)

## Redis 的数据类型及使用场景

### String

最常规的 set/get 操作，Value 可以是 String 也可以是数字。一般做一些复杂的计数功能的缓存

### Hash

这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。

我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能
很好的模拟出类似 Session 的效果。

### List

使用 List 的数据结构，可以做简单的消息队列的功能。

另外，可以利用 lrange 命令，做基于 Redis的分页功能，性能极佳，用户体验好。

### Set

因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能。

我们的系统一般都是集群部署，使用 JVM 自带的 Set 比较麻烦。

另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。

### Sorted Set

Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。

可以做排行榜应用，取 TOP(N) 操作。Sorted Set 可以用来做延时任务。

## 使用 Redis 有哪些好处？

具有以下好处：

- 读取速度快，因为数据存在内存中，所以数据获取快；
- 支持多种数据结构，包括字符串、列表、集合、有序集合、哈希等；
- 支持事务，且操作遵守原子性，即对数据的操作要么都执行，要么都不支持；
- 还拥有其他丰富的功能，队列、主从复制、集群、数据持久化等功能。

## 为什么 使用 Redis 而不是用 Memcache 呢

1. `Redis` 和 `Memcache` 都是将数据存放在内存中，都是内存数据库。不过 `Memcache` 还可用于缓存其他东西，例如图片、视频等等。
2. `Memcache` 仅支持key-value结构的数据类型，`Redis`不仅仅支持简单的key-value类型的数据，同时还提供`list，set，hash`等数据结构的存储。
3. 存储数据安全– Memcache 挂掉后，数据没了； `Redis` 可以定期保存到磁盘（持久化）
4. `Memcache` 的单个value最大 1m ， `Redis` 的单个value最大 512m
5. `Memcached` 网络IO模型是多线程，非阻塞IO复用的网络模型，原型上接近于 nignx。

   而 `Redis` 使用单线程的IO复用模型，自己封装了一个简单的 AeEvent 事件处理框架，主要实现类epoll，kqueue 和 select ，更接近于Apache早期的模式。

## 为什么 Redis 单线程模型效率也能那么高

1. C语言实现，效率高
2. 纯内存操作
3. 基于非阻塞的IO复用模型机制
4. 单线程的话就能避免多线程的频繁上下文切换问题
5. 丰富的数据结构（全称采用hash结构，读取速度非常快，对数据存储进行了一些优化，比如亚索表，跳表等）

## 说说Redis的线程模型

`Redis` 内部使用文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以`Redis` 才叫做单线程的模型。

它采用 IO 多路复用机制同时监听多个 `socket` ，根据 `socket` 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

1. 多个 socket 。
2. IO 多路复用程序。
3. 文件事件分派器。
4. 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会
监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事
件，把该事件交给对应的事件处理器进行处理。

## Redis持久化方式以及区别

`Redis` 提供两种持久化机制 `RDB` 和 `AOF` 机制:

### `RDB` 持久化方式

是指用数据集快照的方式半持久化模式记录 `redis` 数据库的所有键值对,在某个时间点将数据写入
一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。

### `RDB`优点

- 只有一个文件 dump.rdb ，方便持久化。
- 容灾性好，一个文件可以保存到安全的磁盘。
- 性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单
独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能)
- 相对于数据集大时，比 AOF 的启动效率更高。

### `RDB`缺点

- 数据安全性低。 RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据
丢失。所以这种方式更适合数据要求不严谨的时候

### AOF=Append-only file 持久化方式

是指所有的命令行记录以 `Redis` 命令请求协议的格式完全持久化存储，保存为 `AOF` 文件。

### `AOF`优点

1. 数据安全， AOF 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 AOF 文件中一次。
2. 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。
3. AOF 机制的 rewrite 模式。 AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的 flushall)

### `AOF`缺点

1. AOF 文件比 RDB 文件大，且恢复速度慢。
2. 数据集大的时候，比 RDB 启动效率低。

## Redis如何选择持久化方式

1. 不要仅仅使用 RDB ，因为那样会导致你丢失很多数据。
2. 也不要仅仅使用 AOF ，因为那样有两个问题，第一，你通过 AOF 做冷备没有 RDB 做冷备的恢
复速度更快; 第二， RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备
份和恢复机制的 bug 。
3. Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，
用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF
文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。
4. 如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 AOF 来重新
构建数据，因为 AOF 中的数据更加完整。

## 说说你对Redis事务的理解

### 什么是 Redis 事务？原理是什么？

Redis 中的事务是一组命令的集合，是 Redis 的最小执行单位。它可以保证一次执行多个命令，每
个事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序地执行。服务端在执行事务
的过程中，不会被其他客户端发送来的命令请求打断。
它的原理是先将属于一个事务的命令发送给 Redis，然后依次执行这些命令。

### Redis 事务的注意点有哪些？

**需要注意的点有：**
Redis 事务是不支持回滚的，不像 MySQL 的事务一样，要么都执行要么都不执行；
Redis 服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。直到事务命令全部执行完毕才会执行其他客户端的命令。

### Redis 事务为什么不支持回滚？

Redis 的事务不支持回滚，但是执行的命令有语法错误，Redis 会执行失败，这些问题可以从程序层
面捕获并解决。但是如果出现其他问题，则依然会继续执行余下的命令。这样做的原因是因为回滚
需要增加很多工作，而不支持回滚则可以保持简单、快速的特性

## 简述Redis集群模式

1. Redis Sentinel
体量较小时，选择 Redis Sentinel ，单主 Redis 足以支撑业务。
2. Redis Cluster
Redis 官方提供的集群化方案，体量较大时，选择 Redis Cluster ，通过分片，使用更多内
存。
3. Twemprox
Twemprox 是 Twtter 开源的一个 Redis 和 Memcached 代理服务器，主要用于管理 Redis 和
Memcached 集群，减少与Cache 服务器直接连接的数量。
4. Codis
Codis 是一个代理中间件，当客户端向 Codis 发送指令时， Codis 负责将指令转发到后面的
Redis 来执行，并将结果返回给客户端。一个 Codis 实例可以连接多个 Redis 实例，也可以启
动多个 Codis 实例来支撑，每个 Codis 节点都是对等的，这样可以增加整体的 QPS 需求，还能
起到容灾功能。
5. 客户端分片
在 Redis Cluster 还没出现之前使用较多，现在基本很少热你使用了，在业务代码层实现，起
几个毫无关联的 Redis 实例，在代码层，对 Key 进行 hash 计算，然后去对应的 Redis 实例操
作数据。这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，
数据震荡后的自动脚本恢复，实例的监控，等等。

## RedisCluster集群原理

使用过 Redis 集群，它的原理是：

- 所有的节点相互连接
- 集群消息通信通过集群总线通信，集群总线端口大小为客户端服务端口 + 10000（固定值）
- 节点与节点之间通过二进制协议进行通信
- 客户端和集群节点之间通信和通常一样，通过文本协议进行
- 集群节点不会代理查询
- 数据按照 Slot 存储分布在多个 Redis 实例上
- 集群节点挂掉会自动故障转移
- 可以相对平滑扩/缩容节点

Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对
key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号
在 0~16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。

## RedisCluster集群方案什么情况下会导致整个集群不可用？

Redis 没有使用哈希一致性算法，而是使用哈希槽。Redis 中的哈希槽一共有 16384 个，计算给定
密钥的哈希槽，我们只需要对密钥的 CRC16 取摸 16384。假设集群中有 A、B、C 三个集群节点，
不存在复制模式下，每个集群的节点包含的哈希槽如下：

- 节点 A 包含从 0 到 5500 的哈希槽；
- 节点 B 包含从 5501 到 11000 的哈希槽；
- 节点 C 包含从 11001 到 16383 的哈希槽；
- 这时，如果节点 B 出现故障，整个集群就会出现缺少 5501 到 11000 的哈希槽范围而不可用。

## 缓存和数据库谁先更新呢

1. 写请求过来，将写请求缓存到缓存队列中，并且开始执行写请求的具体操作（删除缓存中的数
据，更新数据库，更新缓存）。
2. 如果在更新数据库过程中，又来了个读请求，将读请求再次存入到缓存队列（可以搞n个队
列，采用key的hash值进行队列个数取模hash%n，落到对应的队列中，队列需要保证顺序性）
中，顺序性保证等待队列前的写请求执行完成，才会执行读请求之前的写请求删除缓存失败，
直接返回，此时数据库中的数据是旧值，并且与缓存中的数据是一致的，不会出现缓存一致性
的问题。
3. 写请求删除缓存成功，则更新数据库，如果更新数据库失败，则直接返回，写请求结束，此时
数据库中的值依旧是旧值，读请求过来后，发现缓存中没有数据， 则会直接向数据库中请求，
同时将数据写入到缓存中，此时也不会出现数据一致性的问题。
4. 更新数据成功之后，再更新缓存，如果此时更新缓存失败，则缓存中没有数据，数据库中是新
值 ，写请求结束，此时读请求还是一样，发现缓存中没有数据，同样会从数据库中读取数据，
并且存入到缓存中，其实这里不管更新缓存成功还是失败， 都不会出现数据一致性的问题。
上面这方案解决了数据不一致的问题，主要是使用了串行化，每次操作进来必须按照顺序进行。如
果某个队列元素积压太多，可以针对读请求进行过滤，提示用户刷新页面，重新请求。
潜在的问题，留给大家自己去想吧，因为这个问题属于发散性。
1，请求时间过长，大量的写请求堆压在队列中，一个读请求来得等都写完了才可以获取到数据。
2，读请求并发高
3，热点数据路由问题，导致请求倾斜。

## 怎么提高缓存命中率

**主要常用的手段有：**

- 提前加载数据到缓存中；
- 增加缓存的存储空间，提高缓存的数据；
- 调整缓存的存储数据类型；
- 提升缓存的更新频率。

## 如果有大量的key需要设置同一时间过期，一般需要注意什么

**现象**
如果有大量的 key 在同一时间过期，那么可能同一秒都从数据库获取数据，给数据库造成很大的压
力，导致数据库崩溃，系统出现 502 问题。也有可能同时失效，那一刻不用都访问数据库，压力不
够大的话，那么 Redis 会出现短暂的卡顿问题。

**解决办法**
所以为了预防这种问题的发生，最好给数据的过期时间加一个随机值，让过期时间更加分散。

## 缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等问题

### 一、缓存雪崩

**现象：**
我们可以简单的理解为：由于原有缓存失效，新缓存未到期间 (例如：我们设置缓存时采用了相同的
过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，
而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成
整个系统崩溃。

**解决办法：**

- 大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。
- 还有一个简单方案就时讲缓存失效时间分散开。

### 二、缓存穿透

**现象：**
缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用
户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次
无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。 

**解决办法：**

- 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不
存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 

- 另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然
把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值
存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。
5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些32bit大小的数
据该如何解决？如果是64bit的呢？
对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。 Bitmap： 典型的就
是哈希表 缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠
牺牲更多的空间、时间来完成了。
布隆过滤器（推荐） 就是引入了k(k>1)k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率
下，完成元素判重的过程。 它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定
的误识别率和删除困难。 Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲
突”。 Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减
少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那
么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存
在于集合中。这便是Bloom-Filter的基本思想。 Bloom-Filter一般用于在大数据量的集合中判定某
元素是否存在。

### 三、缓存预热

**现象：**
缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理
解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请
求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据

**解决办法：**

1. 直接写个缓存刷新页面，上线时手工操作下；
2. 数据量不大，可以在项目启动的时候自动进行加载
3. 定时刷新缓存

### 四、缓存更新

除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们
还可以根据具体的业务需求进行自定义的缓存淘汰，

**常见的策略有两种：**

1. 定时去清理过期的缓存；
2. 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存.

   两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！
   具体用哪种方案，大家可以根据自己的应用场景来权衡。

### 五、缓存降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流
程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自
动降级，也可以配置开关实现人工降级。

**降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。**

**以参考日志级别设置预案：**

（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 
（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； 
（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大
阀值，此时可以根据情况自动降级或者人工降级；
（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重
要的缓存数据，可以采取服务降级策略，

例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。

## Redis的数据淘汰策略

如果一个键是过期的，那他到了过期时间后是不是马上就从内存上被删除呢？不是马上。

### 过期键的清除策略：定时删除和惰性删除

- 定时清除：对CPU不好，拿CPU性能换取内存的存储空间

CPU遍历redis，查找到所有过期的数据并删除。消耗CPU，产生大量的性能消耗，同时也会影响数据的操作和读取

- 惰性清除：对内存不友好，产生大量垃圾。造成内存泄漏的隐患

数据到达过期时间，不做处理。下次访问的时候，未过期，返回数据；过期：删除数据，返回不存在

### 总结：上述两种过期键清除策略都比较极端

### 解决方案：内存淘汰策略设置

redis的内存淘汰策略（默认配置：maxmemory-policy noeviction）

- noeviction：不会驱逐任何key（默认配置）
- volatile-ttl：删除马上要过期的key
- allkeys-lru：对所有的key实行LRU算法进行删除（最常见）
- allkeys-lfu：对所有的key实行LFU算法进行删除
- allkeys-random：对所有的key随机删除
- volatile-lru：对设置了过期时间的key实行LRU算法进行删除
- volatile-lfu：对设置了过期时间的key实行LFU算法进行删除
- volatile-random：对设置了过期时间的key随机删除

**LRU和LFU**
LRU：means Least Recently Used    选择最近最久没有使用的数据予以淘汰
LFU：means Least Frequently Used

**过期和淘汰的区别**
过期了不一定淘汰，淘汰是内存满了后按照淘汰策略进行删除数据

## 简述Redis热点Key及其解决方案

在Redis中，访问频率高的key称为热点key。

### 产生原因和危害

#### 原因

热点问题产生的原因大致有以下两种：

用户消费的数据远大于生产的数据（热卖商品、热点新闻、热点评论、明星直播）。

在日常工作生活中一些突发的事件，例如：双十一期间某些热门商品的降价促销，当这其中的某一件商品被数万次点击浏览或者购买时，会形成一个较大的需求量，这种情况下就会造成热点问题。同理，被大量刊发、浏览的热点新闻、热点评论、明星直播等，这些典型的读多写少的场景也会产生热点问题。

请求分片集中，超过单Server的性能极限。在服务端读数据进行访问时，往往会对数据进行分片切分，此过程中会在某一主机Server上对相应的Key进行访问，当访问超过Server极限时，就会导致热点Key问题的产生。

#### 危害

1、流量集中，达到物理网卡上限。

2、请求过多，缓存分片服务被打垮。

3、DB击穿，引起业务雪崩。

### 发现热点key

#### 预估发现

针对业务提前预估出访问频繁的热点key，例如秒杀商品业务中，秒杀的商品都是热点key。

当然并非所有的业务都容易预估出热点key，可能出现漏掉或者预估错误的情况。

#### 客户端发现

客户端其实是距离key"最近"的地方，因为Redis命令就是从客户端发出的，以Jedis为例，可以在核心命令入口，使用这个Google Guava中的AtomicLongMap进行记录，如下所示。

使用客户端进行热点key的统计非常容易实现，但是同时问题也非常多：

(1) 无法预知key的个数，存在内存泄露的危险。

(2) 对于客户端代码有侵入，各个语言的客户端都需要维护此逻辑，维护成本较高。

(3) 规模化汇总实现比较复杂。

#### Redis发现

##### monitor命令

monitor命令可以监控到Redis执行的所有命令，利用monitor的结果就可以统计出一段时间内的热点key排行榜，命令排行榜，客户端分布等数据。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/8aceffd9136f47d5a20466ae69ed46ba.png)

Facebook开源的redis-faina正是利用上述原理使用Python语言实现的，例如下面获取最近10万条命令的热点key、热点命令、耗时分布等数据。为了减少网络开销以及加快输出缓冲区的消费速度，monitor尽可能在本机执行。

**此种方法会有两个问题：**

1、monitor命令在高并发条件下，内存暴增同时会影响Redis的性能，所以此种方法适合在短时间内使用。

2、只能统计一个Redis节点的热点key，对于Redis集群需要进行汇总统计。

**可以参考的框架：Facebook开源的redis-faina正是利用上述原理使用Python语言实现的**

##### hotkeys

Redis在4.0.3中为redis-cli提供了--hotkeys，用于找到热点key。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/9b76d5e60f9241688cad544007026736.png)

如果有错误，需要先把内存逐出策略设置为allkeys-lfu或者volatile-lfu，否则会返回错误。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/bad34aec274f46aa88c00f3adc35f259.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/e1ee50492b024688ab2aaa45ee49859b.png)

但是如果键值较多，执行较慢，和热点的概念的有点背道而驰，同时热度定义的不够准确。

#### 抓取TCP包发现

Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。如果站在机器的角度，可以通过对机器上所有Redis端口的TCP数据包进行抓取完成热点key的统计

此种方法对于Redis客户端和服务端来说毫无侵入，是比较完美的方案，但是依然存在3个问题：

(1) 需要一定的开发成本

(2) 对于高流量的机器抓包，对机器网络可能会有干扰，同时抓包时候会有丢包的可能性。

(3) 维护成本过高。

对于成本问题，有一些开源方案实现了该功能，例如ELK(ElasticSearch Logstash Kibana)体系下的packetbeat[2] 插件，可以实现对Redis、MySQL等众多主流服务的数据包抓取、分析、报表展示

### 解决热点key

发现热点key之后，需要对热点key进行处理。

#### 使用二级缓存

可以使用 guava-cache或hcache，发现热点key之后，将这些热点key加载到JVM中作为本地缓存。访问这些key时直接从本地缓存获取即可，不会直接访问到redis层了，有效的保护了缓存服务器。

#### key分散

将热点key分散为多个子key，然后存储到缓存集群的不同机器上，这些子key对应的value都和热点key是一样的。当通过热点key去查询数据时，通过某种hash算法随机选择一个子key，然后再去访问缓存机器，将热点分散到了多个子key上。

## 十七、讲一讲Redis缓存的数据一致性问题和处理方案

### 数据一致性

只要使用到缓存，无论是本地内存做缓存还是使用 redis 做缓存，那么就会存在数据同步的问题。

我以 Tomcat 向 MySQL 中写入和删改数据为例，来给你解释一下，数据的增删改操作具体是如何进行的。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/5a0bb5a11d0d41648dd390c8fecdc6ec.png)![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/c1723be2ec76469eac667f9210beeede.png)

我们分析一下几种解决方案，

1、先更新缓存，再更新数据库

2、先更新数据库，再更新缓存

3、先删除缓存，后更新数据库

4、先更新数据库，后删除缓存

#### 新增数据类

如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，此时，缓存和数据库的数据是一致的。

#### 更新缓存类

##### 1、先更新缓存，再更新DB

这个方案我们一般不考虑。原因是更新缓存成功，更新数据库出现异常了，导致缓存数据与数据库数据完全不一致，而且很难察觉，因为缓存中的数据一直都存在。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1667197328004/99fa32b1074d4952b2e17ca8dc39ebc4.png)

##### 2、先更新DB，再更新缓存

这个方案也我们一般不考虑，原因跟第一个一样，数据库更新成功了，缓存更新失败，同样会出现数据不一致问题。同时还有以下问题

*1* *）并发问题：*

*同时有请求A**和请求B**进行更新操作，那么会出现*

*（1* *）线程A*更新了数据库

*（2* *）线程B*更新了数据库

*（3* *）线程B*更新了缓存

*（4* *）线程A*更新了缓存

*这就出现请求A**更新缓存应该比请求B**更新缓存早才对，但是因为网络等原因，B**却比A**更早更新了缓存。这就导致了脏数据，因此不考虑。*

*2* *）业务场景问题*

*如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。*

**除了更新缓存之外，我们还有一种就是删除缓存。**

到底是选择更新缓存还是淘汰缓存呢？

主要取决于“更新缓存的复杂度”，更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率，更新缓存的代价很大，此时我们应该更倾向于淘汰缓存。

#### 删除缓存类

##### 3、先删除缓存，后更新DB

该方案也会出问题，具体出现的原因如下。

1、此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）

2、请求 A 会先删除 Redis 中的数据，然后去数据库进行更新操作；

3、此时请求 B 看到 Redis 中的数据时空的，会去数据库中查询该值，补录到 Redis 中；

4、但是此时请求 A 并没有更新成功，或者事务还未提交，请求B去数据库查询得到旧值；

5、那么这时候就会产生数据库和 Redis 数据不一致的问题。

如何解决呢？其实最简单的解决办法就是延时双删的策略。就是

（1）先淘汰缓存

（2）再写数据库

（3）休眠1秒，再次淘汰缓存

**这段伪代码就是“延迟双删”**

```java
redis.delKey(X)
db.update(X)
Thread.sleep(N)
redis.delKey(X)
```

这么做，可以将1秒内所造成的缓存脏数据，再次删除。

那么，这个1秒怎么确定的，具体该休眠多久呢？

针对上面的情形，读该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

但是上述的保证事务提交完以后再进行删除缓存还有一个问题，就是如果你使用的是** Mysql ****的读写分离的架构**的话，那么其实主从同步之间也会有时间差。

此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）

请求 A 更新操作，删除了
Redis，

请求主库进行更新操作，主库与从库进行同步数据的操作，

请 B 查询操作，发现 Redis
中没有数据，

去从库中拿去数据，此时同步数据还未完成，拿到的数据是旧数据。

此时的解决办法有两个：

1、还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

2、就是如果是对 Redis
进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。

继续深入，**采用这种同步淘汰策略，吞吐量降低怎么办？**

那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

继续深入，**第二次删除,如果删除失败怎么办？**

所以，我们引出了，下面的第四种策略，先更新数据库，再删缓存。

##### 4、先更新DB，后删除缓存

这种方式，被称为Cache Aside Pattern，读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。更新的时候，先更新数据库，然后再删除缓存。

### 如何选择问题

一般在线上，更多的偏向与使用删除缓存类操作，因为这种方式的话，会更容易避免一些问题。

因为删除缓存更新缓存的速度比在DB中要快一些，所以一般情况下我们可能会先用先更新DB，后删除缓存的操作。因为这种情况下缓存不一致性的情况只有可能是查询比删除慢的情况，而这种情况相对来说会少很多。同时结合延时双删的处理，可以有效的避免缓存不一致的情况。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1677216030054/a3b42875f99e4f05961354dd5f28c051.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/5983/1677216030054/87fa7bb039c940d0b6038d9d6469e506.png)

## 哪些操作会阻塞redis

redis阻塞的原因有很多。

1. CPU饱和：redis采用单线程，只能使用一个CPU，当CPU使用率过高，就会出现阻塞。
2. API或数据结构使用不合理：
3. redis连接拒绝（超过客户端最大连接数）
4. 两个很大的集合作并集，交集操作，复杂度O(N)，必然阻塞。
5. 慢查询：一次性取出很多key
6. 大量key同时过期也会阻塞
7. 大对象，bigkeys
8. 网络问题:网络延迟
9. 持久化阻塞：

- fork阻塞： fork操作发生在rdb和aof重写时,redis主线程调用fork操作产生共享内存的子进程,由子进程完成持久化文件重写工作,若fork操作本身耗时过长,则必会导致主线程阻塞；可执行info stats命令获取到latest_fork_usec指标,表示redis最近一次fork操作耗时,若超过1s,则需要做出优化调整。
- aof刷盘阻塞： 当开启aof持久化功能时,文件刷盘的方式一般采用每秒一次,后台线程每秒对aof文件做fsync操作,硬盘压力过大时,fsync操作需要等待,直到写入完成如果主线程发现距离上一次的fsync成功超过2秒,为了数据安全性它会阻塞直到后台线程执行fsync操作完成,这种阻塞行为主要是硬盘压力引起,可查看Redis日志识别出这种情况
